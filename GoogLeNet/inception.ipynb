{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inception.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUxdS8aMpxWG",
        "colab_type": "text"
      },
      "source": [
        "## 一、数据预处理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_u_SaURp89N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 导入依赖包\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuXC6cilcsv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "757f0b37-f3be-460b-bbac-7c06c9c0564f"
      },
      "source": [
        "# 数据处理\n",
        "tf.random.set_seed(22)\n",
        "np.random.seed(22)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "batchsize = 512\n",
        "\n",
        "def preprocess(x, y):  #数据预处理\n",
        "    x = tf.cast(x, dtype=tf.float32)/ 255. - 0.5\n",
        "    y = tf.cast(y, dtype=tf.int32)\n",
        "    return x,y\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "\n",
        "# [b, 28, 28] => [b, 28, 28, 1]\n",
        "x_train, x_test = np.expand_dims(x_train, axis=3), np.expand_dims(x_test, axis=3)\n",
        "\n",
        "#训练集预处理\n",
        "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) # 构造数据集,这里可以自动的转换为tensor类型了\n",
        "db_train = db_train.map(preprocess).shuffle(10000).batch(batchsize)\n",
        "\n",
        "#测试集预处理\n",
        "db_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) # 构造数据集\n",
        "db_test = db_test.map(preprocess).shuffle(10000).batch(batchsize)\n",
        "\n",
        "db_iter = iter(db_train)\n",
        "sample = next(db_iter)\n",
        "print(\"batch: \", sample[0].shape, sample[1].shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "batch:  (512, 28, 28, 1) (512,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXX6esLBq4tI",
        "colab_type": "text"
      },
      "source": [
        "## 二、构建CNN基本单元Conv+BN+Relu类模块\n",
        "基本的卷积神经网络单元由：卷积层+批量归一化+激活层！\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c9SmYvJeUYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBNRelu(keras.Model):\n",
        "  def __init__(self, ch, kernelsz=3, strides=1, padding='same'):\n",
        "    super(ConvBNRelu, self).__init__()\n",
        "\n",
        "    self.model = keras.models.Sequential([\n",
        "        keras.layers.Conv2D(ch, kernelsz, strides=strides, padding=padding), # 卷积\n",
        "        keras.layers.BatchNormalization(), # 批量归一化\n",
        "        keras.layers.ReLU() # 激活函数\n",
        "    ])\n",
        "      \n",
        "  def call(self, x, training=None):\n",
        "    x = self.model(x, training=training)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyX-J07frMRV",
        "colab_type": "text"
      },
      "source": [
        "三、构建Inception Block模块\n",
        "![](https://freeshow.oss-cn-beijing.aliyuncs.com/blog/20200421105955.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd70wAAqfFmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionBlk(keras.Model):\n",
        "\n",
        "  def __init__(self, ch, strides=1):\n",
        "    super(InceptionBlk, self).__init__()\n",
        "    # channel\n",
        "    self.ch = ch                                        \n",
        "    self.strides = strides \t\t\t\t\t\t\t\t\n",
        "\n",
        "    self.conv1 = ConvBNRelu(ch, strides=strides) # 构造第1个CNN基本单元\n",
        "    self.conv2 = ConvBNRelu(ch, kernelsz=3, strides=strides) # 构造第2个CNN基本单元，卷积核大小初始为3*3\n",
        "    self.conv3_1 = ConvBNRelu(ch, kernelsz=3, strides=strides) # 构造第3_1个CNN基本单元，卷积核大小初始为3*3\n",
        "    self.conv3_2 = ConvBNRelu(ch, kernelsz=3, strides=1) # 构造第3_2个CNN基本单元，卷积核大小初始为3*3\n",
        "\n",
        "    self.pool = keras.layers.MaxPooling2D(3, strides=1, padding='same') # 最大池化层，same\n",
        "    self.pool_conv = ConvBNRelu(ch, strides=strides) # 构造CNN基本单元，卷积核大小初始为3*3\n",
        "\n",
        "  def call(self, x, training=None):\n",
        "    x1 = self.conv1(x, training=training)\n",
        "    x2 = self.conv2(x, training=training)\n",
        "\n",
        "    x3_1 = self.conv3_1(x, training=training)\n",
        "    x3_2 = self.conv3_2(x3_1, training=training)\n",
        "\n",
        "    x4 = self.pool(x)\n",
        "    x4 = self.pool_conv(x4, training=training)\n",
        "    # concat along axis=channel\n",
        "    x = tf.concat([x1, x2, x3_2, x4], axis=3) # 通道数扩充，上图理解。\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZROY8cWgsntu",
        "colab_type": "text"
      },
      "source": [
        "## 三、构建Res Block 模块\n",
        "Res Block 模块继承keras.Model或者keras.Layer都可以\n",
        "\n",
        "![](https://freeshow.oss-cn-beijing.aliyuncs.com/blog/20200421110851.png)\n",
        "\n",
        "一个 Res Block包含多个Inception Block,且其中的每个Inception Block维度相同，第一个Inception Block对上一个Res Block进行降维。\n",
        "\n",
        "下面代码中假设每个Res Block中包含两个Inception Block，第一个Inception Block的strides=2,用于降维，第二个Inception Block的strides=1,保持与第一个Inception Block的维度相同。\n",
        "\n",
        "每个经过一个Res Block后，channel通道数x2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxVkx0Jvg1hx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Res Block 模块。继承keras.Model或者keras.Layer都可以\n",
        "class Inception(keras.Model):\n",
        "\n",
        "  def __init__(self, num_layers, num_classes, init_ch=16, **kwargs):\n",
        "    super(Inception, self).__init__(**kwargs)\n",
        "\n",
        "    self.init_ch = init_ch # 初始通道\n",
        "    self.out_channels = init_ch # 初始输出通道数\n",
        "    self.num_layers = num_layers # 初始层数，就是多少个res block\n",
        "\n",
        "    self.conv1 = ConvBNRelu(self.init_ch) # 构造1个CNN基本单元\n",
        "\n",
        "    self.blocks = keras.models.Sequential(name='dynamic-blocks') # 创建一个Sequential容器对象\n",
        "\n",
        "    # 创建num_layers个Res Block\n",
        "    for block_id in range(num_layers):\n",
        "\n",
        "      # 每个Res Block中包含2个Inception Block\n",
        "      for layer_id in range(2):\t\n",
        "        # 如果是第一个Inception Block  \n",
        "        if layer_id == 0:\t\n",
        "          # 则strides=2,进行数据降维  \n",
        "          block = InceptionBlk(self.out_channels, strides=2) \n",
        "\n",
        "        else:\t# 如果是第二个Inception Block,则strides=1,维度保持与第一个Inception Block一样\n",
        "          block = InceptionBlk(self.out_channels, strides=1)\n",
        "\n",
        "        self.blocks.add(block) # 把block放进容器对象blocks中\n",
        "\n",
        "      # 添加完一层Res Block后，将通道数扩大为2倍。\n",
        "      self.out_channels *= 2\n",
        "\n",
        "    self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
        "    self.fc = keras.layers.Dense(num_classes)\n",
        "\n",
        "  def call(self, x, training=None):\n",
        "    out = self.conv1(x, training=training)\n",
        "    out = self.blocks(out, training=training)\n",
        "    out = self.avg_pool(out)\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3uLxzVFygre",
        "colab_type": "text"
      },
      "source": [
        "## 四、构建网络"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISAvzdZZyjkg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "600f0a6e-4998-4c2f-90dc-6681a9b6c6c4"
      },
      "source": [
        "# 调用Inception\n",
        "model = Inception(2, 10) # 第1参数为Res Block的数目，第2个参数为类别数；\n",
        "# derive input shape for every layers.\n",
        "model.build(input_shape=(None, 28, 28, 1))\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_bn_relu (ConvBNRelu)    multiple                  224       \n",
            "_________________________________________________________________\n",
            "dynamic-blocks (Sequential)  multiple                  292704    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  1290      \n",
            "=================================================================\n",
            "Total params: 294,218\n",
            "Trainable params: 293,226\n",
            "Non-trainable params: 992\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX8nbfAwy5ot",
        "colab_type": "text"
      },
      "source": [
        "## 五、模型训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0odrmJVy7gZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTYwWzitzi4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c4b3bc0b-6517-441f-e081-76ca87854e02"
      },
      "source": [
        "model.fit(db_train, epochs=10, validation_data=db_test, validation_freq=2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "118/118 [==============================] - 8s 68ms/step - loss: 0.5951 - accuracy: 0.7967\n",
            "Epoch 2/10\n",
            "118/118 [==============================] - 9s 77ms/step - loss: 0.3078 - accuracy: 0.8916 - val_loss: 2.6047 - val_accuracy: 0.1435\n",
            "Epoch 3/10\n",
            "118/118 [==============================] - 8s 67ms/step - loss: 0.2546 - accuracy: 0.9086\n",
            "Epoch 4/10\n",
            "118/118 [==============================] - 9s 74ms/step - loss: 0.2177 - accuracy: 0.9219 - val_loss: 0.8816 - val_accuracy: 0.7115\n",
            "Epoch 5/10\n",
            "118/118 [==============================] - 8s 67ms/step - loss: 0.1950 - accuracy: 0.9302\n",
            "Epoch 6/10\n",
            "118/118 [==============================] - 9s 76ms/step - loss: 0.1737 - accuracy: 0.9370 - val_loss: 0.4438 - val_accuracy: 0.8553\n",
            "Epoch 7/10\n",
            "118/118 [==============================] - 8s 67ms/step - loss: 0.1537 - accuracy: 0.9459\n",
            "Epoch 8/10\n",
            "118/118 [==============================] - 9s 74ms/step - loss: 0.1365 - accuracy: 0.9509 - val_loss: 0.3366 - val_accuracy: 0.8890\n",
            "Epoch 9/10\n",
            "118/118 [==============================] - 8s 68ms/step - loss: 0.1221 - accuracy: 0.9564\n",
            "Epoch 10/10\n",
            "118/118 [==============================] - 9s 72ms/step - loss: 0.1050 - accuracy: 0.9636 - val_loss: 0.4820 - val_accuracy: 0.8635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe720bd5160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}